# from __future__ import annotations
# import os
# import sys
# import re
# from pathlib import Path
# from typing import Dict, List
#
# from bs4 import BeautifulSoup
# from selenium import webdriver
# from selenium.webdriver.common.by import By
# from selenium.webdriver.support import expected_conditions as EC
# from selenium.webdriver.support.ui import WebDriverWait
# from selenium.webdriver.remote.webdriver import WebDriver
# import random
# from src.sdk.queues.redis_connect import get_redis_sync as get_redis
#
#
# FLAG_QUEUES: Dict[str, str] = {
#     "PumpSwap": os.getenv("PUMP_QUEUE",    "pump_queue"),
#     "Raydium":  os.getenv("RAYDIUM_QUEUE", "raydium_queue"),
#     "Meteora":  os.getenv("METEORA_QUEUE", "meteora_queue"),
# }
# RESET_TOKENS_QUEUE = os.getenv("RESET_TOKENS_QUEUE", "0") == "1"
# PROXY_FILE = Path("src/scraper/dexscreener/proxies.txt")
# sys.stdout.reconfigure(line_buffering=True)  # Ğ¿Ñ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ»Ğ¾Ğ³Ğ¸ ÑÑ€Ğ°Ğ·Ñƒ
#
#
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Redis helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def push_tokens(tokens: List[str], queue: str) -> None:
#     """ĞšĞ»Ğ°Ğ´Ñ‘Ñ‚ Ğ°Ğ´Ñ€ĞµÑĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ² Redis-Ğ»Ğ¸ÑÑ‚ `queue` (Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñƒ)."""
#     if not tokens:
#         return
#
#     rds = get_redis()
#     if RESET_TOKENS_QUEUE:
#         rds.delete(queue)
#         print(f"ğŸ§¹  ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ğ»Ğ¸ Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ {queue}")
#
#     rds.rpush(queue, *tokens)
#     print(f"ğŸšš  ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¸ {len(tokens)} Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² â†’ {queue}")
#
# def _pick_random_proxy() -> str | None:
#     """
#     Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑÑ‚Ñ€Ğ¾ĞºÑƒ ip:port Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°, Ğ»Ğ¸Ğ±Ğ¾ None,
#     ĞµÑĞ»Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ½ĞµÑ‚ / ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹.
#     """
#     if not PROXY_FILE.exists():
#         print("[warn] proxies.txt not found â€“ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµĞ¼ Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾ĞºÑĞ¸")
#         return None
#     proxies = [ln.strip() for ln in PROXY_FILE.read_text().splitlines() if ln.strip()]
#     if not proxies:
#         print("[warn] proxies.txt empty â€“ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµĞ¼ Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾ĞºÑĞ¸")
#         return None
#     return random.choice(proxies)
#
# def _get_driver() -> WebDriver:
#     grid_url = os.getenv("SELENIUM_SERVER_URL", "http://localhost:4444/wd/hub")
#
#     opts = webdriver.ChromeOptions()
#     opts.add_argument("--no-sandbox")
#     opts.add_argument("--disable-dev-shm-usage")
#     opts.add_argument("--disable-extensions")
#     opts.add_argument("--disable-gpu")
#     opts.add_argument("--disable-infobars")
#
#     # â”€â”€â”€ Ğ¿Ñ€Ğ¾ĞºÑĞ¸ â”€â”€â”€
#     if (proxy := _pick_random_proxy()):
#         opts.add_argument(f"--proxy-server=http://{proxy}")
#         print(f"[proxy] use {proxy}")
#
#     return webdriver.Remote(command_executor=grid_url, options=opts)
#
#
# def _wait_table(driver: WebDriver, timeout: int = 600):
#     """Ğ–Ğ´Ñ‘Ğ¼ Ğ¿Ğ¾ÑĞ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ CAPTCHA."""
#     sel = "div.ds-dex-table.ds-dex-table-top"
#     return WebDriverWait(driver, timeout).until(
#         EC.presence_of_element_located((By.CSS_SELECTOR, sel))
#     )
#
#
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HTML parser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# _token_src_re = re.compile(r"/tokens/solana/([A-Za-z0-9]+)\.png", re.IGNORECASE)
# FLAGS = list(FLAG_QUEUES.keys())  # ["PumpSwap", "Raydium", "Meteora"]
#
#
# def extract_tokens_by_flag(html: str, flags: List[str] = FLAGS) -> Dict[str, List[str]]:
#     """
#     Ğ’Ñ‹Ğ´Ñ‘Ñ€Ğ³Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ°Ğ´Ñ€ĞµÑĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑÑƒÑÑ‰ĞµĞ¼Ñƒ Ñ„Ğ»Ğ°Ğ³Ñƒ.
#     Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ {flag: [addr, â€¦]}.
#     """
#     soup = BeautifulSoup(html, "html.parser")
#     result: Dict[str, List[str]] = {flag: [] for flag in flags}
#
#     for row in soup.select("a.ds-dex-table-row"):
#         flag_found: str | None = None
#         # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼, Ğº ĞºĞ°ĞºĞ¾Ğ¼Ñƒ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºÑƒ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ÑÑ ÑÑ‚Ñ€Ğ¾ĞºĞ°
#         for flag in flags:
#             if row.select_one(f'img[title="{flag}" i]'):
#                 flag_found = flag
#                 break
#         if flag_found is None:
#             continue  # Ğ½Ğ¸ Ğ¾Ğ´Ğ¸Ğ½ Ğ¸Ğ· Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑÑƒÑÑ‰Ğ¸Ñ… Ñ„Ğ»Ğ°Ğ³Ğ¾Ğ² Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½
#
#         # Ğ˜Ñ‰ĞµĞ¼ Ğ¸ĞºĞ¾Ğ½ĞºÑƒ Ñ‚Ğ¾ĞºĞµĞ½Ğ°, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ²Ñ‹Ñ‚Ğ°Ñ‰Ğ¸Ñ‚ÑŒ Ğ°Ğ´Ñ€ĞµÑ Ğ¸Ğ· ĞµÑ‘ src
#         icon = row.select_one(
#             "img.ds-dex-table-row-token-icon-img[src*='/tokens/solana/']"
#         )
#         if not icon:
#             continue
#
#         m = _token_src_re.search(icon["src"])
#         if m:
#             result[flag_found].append(m.group(1))
#
#     # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ¿Ğ¾Ñ€ÑĞ´Ğ¾Ğº
#     for flag, lst in result.items():
#         result[flag] = list(dict.fromkeys(lst))
#
#     return result
#
#
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Scraper core â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def run(max_age_hours: int, out_dir: Path) -> str:
#     """
#     Ğ—Ğ°Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ HTML Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ DexScreener.
#     Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ HTML ĞºĞ°Ğº ÑÑ‚Ñ€Ğ¾ĞºÑƒ.
#     """
#     url = (
#         "https://dexscreener.com/solana"
#         f"?rankBy=trendingScoreH6&order=desc&minMarketCap=50000&maxAge={max_age_hours}"
#     )
#     print("[open]", url)
#
#     driver = _get_driver()
#     try:
#         driver.get(url)
#         print("[wait] Solve CAPTCHA via VNC; waiting for tableâ€¦")
#         table_el = _wait_table(driver)
#
#         # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ HTML (Ğ¿Ñ€Ğ¸Ğ³Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸)
#         out_dir.mkdir(parents=True, exist_ok=True)
#         html = table_el.get_attribute("outerHTML")
#         (out_dir / "last_table.html").write_text(html, encoding="utf-8")
#
#         return html
#
#     finally:
#         driver.quit()
#         print("[quit] browser closed")
#
#
# def run_and_push(max_age_hours: int, out_dir: Path) -> Dict[str, List[str]]:
#     """
#     ĞŸĞ°Ñ€ÑĞ¸Ñ‚ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ, Ñ€Ğ°ÑĞºĞ»Ğ°Ğ´Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¿Ğ¾ Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑĞ¼ Redis
#     Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ {flag: [addresses]}.
#     """
#     html = run(max_age_hours, out_dir)
#     tokens_by_flag = extract_tokens_by_flag(html)
#
#     for flag, tokens in tokens_by_flag.items():
#         push_tokens(tokens, FLAG_QUEUES[flag])
#
#     return tokens_by_flag
#
#
#
# if __name__ == "__main__":
#     hours = int(os.getenv("MAX_AGE_HOURS", "24"))
#     output_dir = Path(os.getenv("OUTPUT_DIR", "./"))
#
#     tokens_by_flag = run_and_push(hours, output_dir)
#
#     for flag, tokens in tokens_by_flag.items():
#         print(f"\n{flag} addresses ({len(tokens)}):")
#         print("\n".join(tokens))
#
#
# src/scraper/meteora/fetch_meteora_tokens.py
from __future__ import annotations
import os
import sys
from pathlib import Path
from typing import List, Dict

from src.sdk.databases.clickhouse.click_connect import get_db
from src.sdk.queues.redis_connect import get_redis_sync as get_redis

# â”€â”€â”€ env â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RESET_TOKENS_QUEUE = os.getenv("RESET_TOKENS_QUEUE", "0") == "1"
MAX_AGE_HOURS      = int(os.getenv("MAX_AGE_HOURS", "24"))
TOKENS_QUEUE       = os.getenv("METEORA_QUEUE",  "meteora_queue")
OUT_DIR            = Path(os.getenv("OUTPUT_DIR", "./"))
sys.stdout.reconfigure(line_buffering=True)

# â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def pick_tokens(age_hours: int) -> List[str]:
    """Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ°Ğ´Ñ€ĞµÑĞ° Ğ¼Ğ¾Ğ½ĞµÑ‚ Meteora, Ğ¿Ğ¾ÑĞ²Ğ¸Ğ²ÑˆĞ¸Ñ…ÑÑ Ğ·Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ `age_hours` Ñ‡Ğ°ÑĞ¾Ğ²."""
    db = get_db()
    query = """
        SELECT DISTINCT coin
        FROM (
            SELECT
                arrayJoin([base_coin, quote_coin]) AS coin,
                min(block_time) AS first_seen
            FROM meteora_swaps
            GROUP BY coin
        )
        WHERE first_seen >= now() - INTERVAL {hours:UInt32} HOUR
    """
    rows = db.fetchall(query, params={"hours": age_hours})
    # ClickHouse Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ¾Ñ‚Ğ´Ğ°Ñ‘Ñ‚ ĞºĞ¾Ñ€Ñ‚ĞµĞ¶Ğ¸; Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ğ² ÑĞ¿Ğ¸ÑĞ¾Ğº ÑÑ‚Ñ€Ğ¾Ğº
    return [r[0] if not isinstance(r, dict) else r["coin"] for r in rows]

def push_tokens(tokens: List[str], queue: str) -> None:
    """ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒÑ Ğ² Redisâ€Ğ»Ğ¸ÑÑ‚ `queue`."""
    if not tokens:
        return
    rds = get_redis()
    if RESET_TOKENS_QUEUE:
        rds.delete(queue)
        print(f"ğŸ§¹  ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ğ»Ğ¸ Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ {queue}")

    rds.rpush(queue, *tokens)
    print(f"ğŸšš  ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¸ {len(tokens)} Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² â†’ {queue}")

# â”€â”€â”€ entrypoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    OUT_DIR.mkdir(parents=True, exist_ok=True)

    tokens = pick_tokens(MAX_AGE_HOURS)
    (OUT_DIR / "meteora_tokens.txt").write_text("\n".join(tokens), encoding="utf-8")

    push_tokens(tokens, TOKENS_QUEUE)

    print(f"\nMeteora addresses ({len(tokens)}):")
    print("\n".join(tokens))
